{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e3f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e9dd7e",
   "metadata": {},
   "source": [
    "## 1. Fine-tuning Mistral-7B-Instruct on Chillies IELTS dataset - LoraConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e9e18",
   "metadata": {},
   "source": [
    "### 1.1 Fine-tuning Mistral-7B-Instruct on Chillies IELTS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# —————————————————————————————\n",
    "# Fine-tuning Mistral-7B-Instruct on Chillies IELTS dataset\n",
    "# —————————————————————————————\n",
    "\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# --- 1. Load dataset\n",
    "ds = load_dataset(\"chillies/IELTS-writing-task-2-evaluation\")\n",
    "\n",
    "# Có các split: train, test\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]\n",
    "\n",
    "# --- 2. Preprocess: tạo `completion` JSON từ field `evaluation`\n",
    "\n",
    "def parse_evaluation_to_json(eva: str):\n",
    "    \"\"\"\n",
    "    Chuyển chuỗi evaluation thành dict JSON:\n",
    "    {\n",
    "       \"TaskResponse\": float,\n",
    "       \"Coherence\": float,\n",
    "       \"Lexical\": float,\n",
    "       \"Grammar\": float,\n",
    "       \"Overall\": float,\n",
    "       \"Feedback\": str\n",
    "    }\n",
    "    \"\"\"\n",
    "    # dùng regex để tìm các điểm\n",
    "    # Lưu ý: tên tiêu chí có thể khác một chút, cần tùy theo dataset\n",
    "    # Ví dụ \"Task Achievement\" tương ứng TaskResponse\n",
    "    \n",
    "    d = {}\n",
    "    # Task Achievement / Task Response\n",
    "    m = re.search(r\"Task Achievement:\\s*\\[([0-9]*\\.?[0-9]+)\\]\", eva)\n",
    "    if m:\n",
    "        d[\"TaskResponse\"] = float(m.group(1))\n",
    "    # Coherence and Cohesion\n",
    "    m = re.search(r\"Coherence and Cohesion:\\s*\\[([0-9]*\\.?[0-9]+)\\]\", eva)\n",
    "    if m:\n",
    "        d[\"Coherence\"] = float(m.group(1))\n",
    "    # Lexical Resource\n",
    "    m = re.search(r\"Lexical Resource:\\s*\\[([0-9]*\\.?[0-9]+)\\]\", eva)\n",
    "    if m:\n",
    "        d[\"Lexical\"] = float(m.group(1))\n",
    "    # Grammatical Range and Accuracy\n",
    "    m = re.search(r\"Grammatical Range and Accuracy:\\s*\\[([0-9]*\\.?[0-9]+)\\]\", eva)\n",
    "    if m:\n",
    "        d[\"Grammar\"] = float(m.group(1))\n",
    "    # Overall Band Score\n",
    "    m = re.search(r\"Overall Band Score:\\s*\\[([0-9]*\\.?[0-9]+)\\]\", eva)\n",
    "    if m:\n",
    "        d[\"Overall\"] = float(m.group(1))\n",
    "    # Feedback (bắt phần sau “Feedback and Additional Comments:”)\n",
    "    # Giả sử phần feedback bắt đầu từ “Feedback and Additional Comments:”\n",
    "    split_token = \"Feedback and Additional Comments:\"\n",
    "    if split_token in eva:\n",
    "        feedback = eva.split(split_token, 1)[1].strip()\n",
    "        d[\"Feedback\"] = feedback\n",
    "    else:\n",
    "        d[\"Feedback\"] = \"\"\n",
    "    return d\n",
    "\n",
    "def make_completion(example):\n",
    "    d = parse_evaluation_to_json(example[\"evaluation\"])\n",
    "    # convert dict thành JSON string\n",
    "    return json.dumps(d, ensure_ascii=False)\n",
    "\n",
    "# tạo completion và full text (prompt + essay + completion)\n",
    "def make_full_prompt(example):\n",
    "    topic = example[\"prompt\"]\n",
    "    essay = example[\"essay\"]\n",
    "    return f\"### Topic:\\n{topic}\\n\\n### Essay:\\n{essay}\\n\\n### JSON Response:\\n\"\n",
    "\n",
    "def make_full_text(example):\n",
    "    return make_full_prompt(example) + make_completion(example)\n",
    "\n",
    "# Áp map\n",
    "train_ds = train_ds.map(lambda ex: {\"text\": make_full_text(ex)}, remove_columns=train_ds.column_names)\n",
    "test_ds = test_ds.map(lambda ex: {\"text\": make_full_text(ex)}, remove_columns=test_ds.column_names)\n",
    "\n",
    "# --- 3. Tokenizer & model\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # set pad = eos để tránh lỗi\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# --- 4. LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Mistral cần q_proj, v_proj\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# --- 5. Tokenize dataset\n",
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"text\"], truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_fn, batched=False)\n",
    "test_ds = test_ds.map(tokenize_fn, batched=False)\n",
    "\n",
    "# thiết lập format để Trainer hiểu\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "test_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# --- 6. TrainingArguments & Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./mistral_ielts_ft\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# --- 7. Huấn luyện\n",
    "trainer.train()\n",
    "\n",
    "# --- 8. Lưu model & tokenizer\n",
    "model.save_pretrained(\"./mistral_ielts_ft\")\n",
    "tokenizer.save_pretrained(\"./mistral_ielts_ft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a2084",
   "metadata": {},
   "source": [
    "### 1.2 Tích hợp đánh giá MAE / R² sau train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ae298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import re, json\n",
    "import numpy as np\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./mistral_ielts_ft\", tokenizer=\"./mistral_ielts_ft\")\n",
    "\n",
    "preds = []\n",
    "trues = []\n",
    "\n",
    "# dùng test_ds gốc với bản chưa map để lấy điểm thật\n",
    "orig_test = ds[\"test\"]\n",
    "\n",
    "for ex in orig_test:\n",
    "    topic = ex[\"prompt\"]\n",
    "    essay = ex[\"essay\"]\n",
    "    true_eval = parse_evaluation_to_json(ex[\"evaluation\"])\n",
    "    true_overall = true_eval.get(\"Overall\", None)\n",
    "    if true_overall is None:\n",
    "        continue\n",
    "    prompt = f\"### Topic:\\n{topic}\\n\\n### Essay:\\n{essay}\\n\\n### JSON Response:\\n\"\n",
    "    out = pipe(prompt, max_new_tokens=200, temperature=0.5)[0][\"generated_text\"]\n",
    "    # trích JSON từ đầu ra\n",
    "    m = re.search(r\"\\{.*\\}\", out, re.S)\n",
    "    if m:\n",
    "        try:\n",
    "            d = json.loads(m.group(0))\n",
    "            pred = d.get(\"Overall\", None)\n",
    "        except:\n",
    "            pred = None\n",
    "    else:\n",
    "        pred = None\n",
    "    if pred is not None:\n",
    "        preds.append(pred)\n",
    "        trues.append(true_overall)\n",
    "\n",
    "# tính MAE, R²\n",
    "preds = np.array(preds)\n",
    "trues = np.array(trues)\n",
    "print(\"MAE:\", mean_absolute_error(trues, preds))\n",
    "print(\"R²:\", r2_score(trues, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a92b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7e01335",
   "metadata": {},
   "source": [
    "## 2. Fine-tuning Mistral-7B-Instruct-v0.3 with Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd64e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unsloth[cu118] transformers datasets accelerate bitsandbytes peft -U\n",
    "# [cu118] cho CUDA 11.8 (Colab T4)\n",
    "# [cu121] cho CUDA 12.1 (A100)\n",
    "# Unsloth hỗ trợ PyTorch 2.2+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9c5acd",
   "metadata": {},
   "source": [
    "### 2.1 Fine-tuning Mistral-7B-Instruct-v0.3 with Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff713d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Fine-tuning Mistral-7B-Instruct-v0.3 with Unsloth\n",
    "# Dataset: chillies/IELTS-writing-task-2-evaluation\n",
    "# ================================================\n",
    "\n",
    "!pip install unsloth[cu118] transformers datasets accelerate bitsandbytes peft -q -U\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch, re, json\n",
    "\n",
    "# 1️⃣ Load dataset\n",
    "ds = load_dataset(\"chillies/IELTS-writing-task-2-evaluation\")\n",
    "train_ds = ds[\"train\"].shuffle(seed=42).select(range(8000))\n",
    "eval_ds = ds[\"test\"]\n",
    "\n",
    "# 2️⃣ Load model & tokenizer bằng Unsloth\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = 1024,\n",
    "    load_in_4bit = True,          # QLoRA mode\n",
    "    use_gradient_checkpointing = True,\n",
    "    dtype = torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 3️⃣ Add LoRA adapter (rất nhanh)\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 8,                        # Rank 8\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.05,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"],\n",
    "    bias = \"none\",\n",
    "    use_rslora = True,            # RS-LoRA = Robust scaling (giảm overfitting)\n",
    ")\n",
    "\n",
    "# 4️⃣ Preprocess\n",
    "def preprocess(ex):\n",
    "    text = f\"### Topic:\\n{ex['prompt']}\\n\\n### Essay:\\n{ex['essay']}\\n\\n### JSON Response:\\n{ex['evaluation']}\"\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=1024)\n",
    "\n",
    "train_ds = train_ds.map(preprocess)\n",
    "eval_ds = eval_ds.map(preprocess)\n",
    "train_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "eval_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# 5️⃣ TrainingArguments (tối ưu cho Colab Pro)\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./mistral_unsloth_ft\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./mistral_unsloth_ft\")\n",
    "tokenizer.save_pretrained(\"./mistral_unsloth_ft\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509f470",
   "metadata": {},
   "source": [
    "### 2.2 Tích hợp đánh giá MAE / R² sau train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da352c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"./mistral_unsloth_ft\", tokenizer=\"./mistral_unsloth_ft\")\n",
    "\n",
    "preds, trues = [], []\n",
    "for ex in eval_ds.select(range(100)):\n",
    "    text = f\"### Topic:\\n{ex['prompt']}\\n\\n### Essay:\\n{ex['essay']}\\n\\n### JSON Response:\\n\"\n",
    "    out = pipe(text, max_new_tokens=200, temperature=0.5)[0]['generated_text']\n",
    "    m = re.search(r\"\\{.*\\}\", out, re.S)\n",
    "    if m:\n",
    "        try:\n",
    "            js = json.loads(m.group(0))\n",
    "            preds.append(js.get(\"Overall\", None))\n",
    "        except:\n",
    "            preds.append(None)\n",
    "    trues.append(re.search(r\"Overall Band Score:\\s*\\[([\\d\\.]+)\\]\", ex['evaluation']).group(1))\n",
    "\n",
    "mask = [i for i, p in enumerate(preds) if p is not None]\n",
    "y_pred = np.array([preds[i] for i in mask], float)\n",
    "y_true = np.array([float(trues[i]) for i in mask])\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n",
    "print(\"R²:\", r2_score(y_true, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
